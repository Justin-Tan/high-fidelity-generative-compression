{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HiFIC_torch_colab_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53c1556cd96148f1a1f665f778a5ba54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72e7264556154388bb660dbd08cd66b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_258341d884864104b140a1f4a1e315a2",
              "IPY_MODEL_8bb9e32de0fd48929abe5cf948f11ca6"
            ]
          }
        },
        "72e7264556154388bb660dbd08cd66b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258341d884864104b140a1f4a1e315a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72a0342b94b6406da0bc7bebc1ee4ede",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21adf27e097741858be2dec9855c3d65"
          }
        },
        "8bb9e32de0fd48929abe5cf948f11ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ffe5337124e4fc18ab745aa74e70880",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [00:03&lt;00:00, 66.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebf75f25deeb4fe99a40bad9320e0f1d"
          }
        },
        "72a0342b94b6406da0bc7bebc1ee4ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21adf27e097741858be2dec9855c3d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ffe5337124e4fc18ab745aa74e70880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebf75f25deeb4fe99a40bad9320e0f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpm_NksQMtNr",
        "colab_type": "text"
      },
      "source": [
        "# HiFIC Demo\n",
        "Compress arbitrary images in Colab using a pretrained neural compression model. This is a Pytorch port of the [High-Fidelity Image Compression](https://hific.github.io/) project - see the [Github repo](https://github.com/Justin-Tan/high-fidelity-generative-compression) for the source.\n",
        "\n",
        "Execute all cells in sequence to see the results of compression on a default image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Umer7W0VbITT"
      },
      "source": [
        "## Setup Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M227Y3aWcott",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import urllib\n",
        "import zipfile\n",
        "import collections\n",
        "\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from IPython.display import Image as DisplayImage\n",
        "from IPython.display import Javascript\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "INPUT_DIR = '/content/files'\n",
        "STAGING_DIR = '/content/stage'\n",
        "OUT_DIR = '/content/out'\n",
        "CKPT_DIR = '/content/checkpoint'\n",
        "DEFAULT_IMAGE_PREFIX = ('https://storage.googleapis.com/hific/clic2020/images/originals/')\n",
        "File = collections.namedtuple('File', ['output_path', 'compressed_path',\n",
        "                                       'num_bytes', 'bpp'])\n",
        "_ = [os.makedirs(dir, exist_ok=True) for dir in (INPUT_DIR, STAGING_DIR, OUT_DIR,\n",
        "                                                 CKPT_DIR)]\n",
        "first_model_init = False\n",
        "original_sizes = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPU2WMlMZviB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_html(html):\n",
        "    display(HTML(html + '<br/>'))\n",
        "\n",
        "def make_cell_large():\n",
        "    display(Javascript(\n",
        "        '''google.colab.output.setIframeHeight(0, true, {maxHeight: 5192})'''))\n",
        "\n",
        "def get_default_image(output_dir, image_choice=\"portrait\"):\n",
        "    image_ID = dict(cafe=\"b1b8f33917a40c9d0b118ef801de67d4.png\",\n",
        "                    cat=\"4fa92b8ecb4ee46a942837447de1ac5c.png\",\n",
        "                    city=\"b98ec5b29d02ef65e57d23ef90660b4d.png\",\n",
        "                    clocktower=\"9cbf2594f339c0d3d0f0ea25c62af52b.png\",\n",
        "                    fresco=\"8181526d9f238726d3e1d3ec3cc56fb7.png\",\n",
        "                    islet=\"c6658d87c608b631f5cc3fb5a8d89731.png\",\n",
        "                    pasta=\"f5be5054c01d8efc834d78a991356ad6.png\",\n",
        "                    plaza=\"d78b363974ac79908b79012f48de715d.png\",\n",
        "                    portrait=\"ad249bba099568403dc6b97bc37f8d74.png\",\n",
        "                    tundra=\"cc831c904a314a0e98530124526e930b.png\",\n",
        "                    )[image_choice]\n",
        "\n",
        "    default_image_url = os.path.join(DEFAULT_IMAGE_PREFIX, image_ID)\n",
        "    output_path = os.path.join(output_dir, os.path.basename(default_image_url))\n",
        "    print('Downloading', default_image_url, '\\n->', output_path)\n",
        "    urllib.request.urlretrieve(default_image_url, output_path)\n",
        "\n",
        "def get_model_checkpoint(output_dir, model_ID, model_choice, use_zenodo=False,\n",
        "                         overwrite=False):\n",
        "    output_path = os.path.join(output_dir, f'{model_choice.lower()}.pt')\n",
        "    if overwrite is True:\n",
        "        print('Overwriting file.')\n",
        "        !rm -v $output_path\n",
        "    else:\n",
        "        if os.path.exists(output_path):\n",
        "            print('File already exists at', '\\n->', output_path)\n",
        "            return output_path\n",
        "    print('Downloading model to', '\\n->', output_path)\n",
        "    if use_zenodo is True:\n",
        "        !wget \"https://zenodo.org/record/4026003/files/$model_ID\" -O $output_path\n",
        "    else:\n",
        "        !wget -q --show-progress --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$model_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$model_ID\" -O $output_path && rm -rf /tmp/cookies.txt\n",
        "\n",
        "    return output_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiY97nwyJia9",
        "colab_type": "text"
      },
      "source": [
        "## Select Model\n",
        "Higher bitrates result in higher-fidelity reconstructions, at the expense of increased message length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxLn5j7n_an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enter choice to right\n",
        "model_choice = 'HIFIC-low' #@param [\"HIFIC-low\", \"HIFIC-med\", \"HIFIC-high\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA9r_M230r7x",
        "colab_type": "text"
      },
      "source": [
        "Clone repo and grab the model checkpoint (around 2 GB). Please check the downloaded filesize carefully - see below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOPsakQLKJGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ea06a383-3446-4fe2-e3fe-aeb817cb0742"
      },
      "source": [
        "# Drive IDs\n",
        "model_choices = {'HIFIC-low': '1hfFTkZbs_VOBmXQ-M4bYEPejrD76lAY9',\n",
        "                 'HIFIC-med': '1QNoX0AGKTBkthMJGPfQI0dT0_tnysYUb',\n",
        "                 'HIFIC-high': '1BFYpvhVIA_Ek2QsHBbKnaBE8wn1GhFyA'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seLrm41t1wQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "afdb56f3-c5b6-474d-a95e-60aa80a20301"
      },
      "source": [
        "# Checkpoints should be around 2GB in size - if not, run the next\n",
        "# cell to download models from Zenodo\n",
        "!ls -ltrh /content/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrTVlxyi3I83",
        "colab_type": "text"
      },
      "source": [
        "During periods of high traffic the download quota for Google Drive may be temporarily exceeded. Please check (`ls -ltrh /content/checkpoint`) if the checkpoints are around 1.5GB - 2 GB in size. If not, run the cell below this to download the model checkpoints from Zenodo - this is slower but more robust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPIEzUK317Hn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "49f45b38-5ecb-4dbf-ddf8-4295ea9e7284"
      },
      "source": [
        "# Don't run this if the download from Drive was successful!\n",
        "model_choices = {'HIFIC-low': 'hific_low.pt?download=1',\n",
        "                 'HIFIC-med': 'hific_med.pt?download=1',\n",
        "                 'HIFIC-high': 'hific_hi.pt?download=1'}\n",
        "\n",
        "model_ID = model_choices[model_choice]\n",
        "model_path = get_model_checkpoint(CKPT_DIR, model_ID, model_choice, \n",
        "                                  use_zenodo=True, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-50mPz02cKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "04290230-b116-4512-bdfe-ff8d4a4a937c"
      },
      "source": [
        "# Checkpoints should be around 2GB in size\n",
        "!ls -ltrh /content/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0vpM2j1EBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ea249517-5fe7-4e4b-b4bc-b4bb0f36f4bf"
      },
      "source": [
        "!git clone https://github.com/Justin-Tan/high-fidelity-generative-compression.git\n",
        "%cd high-fidelity-generative-compression/\n",
        "from compress import prepare_model, prepare_dataloader, compress_and_save, load_and_decompress, compress_and_decompress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ptGgrzkATB",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Images\n",
        "\n",
        "To upload your own images (JPG or PNG without alpha channels), set `custom_image=True` in the following cell. Otherwise, we'll use a default image from the CLIC2020 Compression Challenge dataset.\n",
        "\n",
        "Alternatively, you can use the `Files` tab on the left and select the `Upload to session storage` icon to upload more custom images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJZlFxcNyK2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_image = False #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LNwIexHmu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose default images from CLIC2020 dataset\n",
        "# Skip if uploading custom images\n",
        "default_image = \"pasta\" #@param [\"cafe\", \"cat\", \"city\", \"clocktower\", \"fresco\", \"islet\", \"pasta\", \"plaza\", \"portrait\", \"tundra\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_S4bo4vhU_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7016de41-4295-4b67-fe0b-2f2ddb6b9e61"
      },
      "source": [
        "if custom_image is True:\n",
        "    print('Using user-defined images.')\n",
        "    # Get dict of upload files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])))\n",
        "        !mv -iv $fn $INPUT_DIR\n",
        "else:\n",
        "    print('Using default image.')\n",
        "    # Download default image\n",
        "    get_default_image(INPUT_DIR, default_image)\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "print(f'Got following files ({len(all_files)}):')\n",
        "scale_factor = 2 if len(all_files) == 1 else 4\n",
        "\n",
        "for file_name in all_files:\n",
        "    img = Image.open(os.path.join(INPUT_DIR, file_name))\n",
        "    w, h = img.size\n",
        "    img = img.resize((w // scale_factor, h // scale_factor))\n",
        "    print('-> ' + file_name + ':')\n",
        "    display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kd02HOhLBj6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6fada6c4-bf73-4a4c-ee7d-0b45ee5bc04b"
      },
      "source": [
        "SUPPORTED_EXT = {'.png', '.jpg'}\n",
        "\n",
        "all_files = os.listdir(INPUT_DIR)\n",
        "if not all_files:\n",
        "    raise ValueError(\"Please upload images!\")\n",
        "\n",
        "def get_bpp(image_dimensions, num_bytes):\n",
        "    w, h = image_dimensions\n",
        "    return num_bytes * 8 / (w * h)\n",
        "\n",
        "def has_alpha(img_p):\n",
        "    im = Image.open(img_p)\n",
        "    return im.mode == 'RGBA'\n",
        "\n",
        "!rm -v $STAGING_DIR/*\n",
        "\n",
        "for file_name in all_files:\n",
        "    if os.path.isdir(file_name):\n",
        "        continue\n",
        "    if not any(file_name.endswith(ext) for ext in SUPPORTED_EXT):\n",
        "        print('Skipping non-image', file_name, '...')\n",
        "        continue\n",
        "    full_path = os.path.join(INPUT_DIR, file_name)\n",
        "    if has_alpha(full_path) is True:\n",
        "        print('Skipping because of alpha channel:', file_name)\n",
        "        continue\n",
        "    \n",
        "    file_name, _ = os.path.splitext(file_name)\n",
        "    original_sizes[file_name] = os.path.getsize(full_path)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "    !mv -v $full_path $STAGING_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nYQ1lZpwWG-",
        "colab_type": "text"
      },
      "source": [
        "## Enabling GPU\n",
        "\n",
        "GPU should be enabled for this Colab. If the next cell prints a warning, do the following:\n",
        "- Navigate to `Edit →> Notebook Settings`\n",
        "- Select GPU from the Hardware Accelerator drop-down\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0U-OwqpwZsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a9a1d3f-0af9-4e33-a5bf-49d12571b10d"
      },
      "source": [
        "if torch.cuda.is_available() is False:\n",
        "  print('WARNING: No GPU found. Compression/decompression will be slow!')\n",
        "else:\n",
        "  print(f'Found GPU {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzaWP_G9w0Wh",
        "colab_type": "text"
      },
      "source": [
        "# Compress Images\n",
        "Note: Models can take up to a minute to load on Colab, depending on the allocated GPU and chosen model - you only need to run the following cell once per session.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeIsfPxcG1Ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "53c1556cd96148f1a1f665f778a5ba54",
            "72e7264556154388bb660dbd08cd66b1",
            "258341d884864104b140a1f4a1e315a2",
            "8bb9e32de0fd48929abe5cf948f11ca6",
            "72a0342b94b6406da0bc7bebc1ee4ede",
            "21adf27e097741858be2dec9855c3d65",
            "5ffe5337124e4fc18ab745aa74e70880",
            "ebf75f25deeb4fe99a40bad9320e0f1d"
          ]
        },
        "outputId": "57ff10d8-6854-4558-d330-694bc9ca3b8b"
      },
      "source": [
        "# Setup model\n",
        "if first_model_init is False:\n",
        "    print('Building model ...')\n",
        "    model, args = prepare_model(model_path, STAGING_DIR)\n",
        "    first_model_init = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij6avY8OyG4I",
        "colab_type": "text"
      },
      "source": [
        "Encode images and save compressed format to disk. Note: depending on the allocated GPU, large images (`>~ 4000x4000 px`) may throw an OOM error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHgSCmS5RRZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "c883a2c8-6797-4817-ff4e-1d5d2a569562"
      },
      "source": [
        "%%time\n",
        "data_loader = prepare_dataloader(args, STAGING_DIR, OUT_DIR)\n",
        "compress_and_save(model, args, data_loader, OUT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FARMLHaa1Crt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b383e71d-6fa9-4c71-ef36-fddfc36f5168"
      },
      "source": [
        "# Check compressed filesizes\n",
        "!ls -ltrh $OUT_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnxLDQ1SyNMU",
        "colab_type": "text"
      },
      "source": [
        "Load compressed format from disk and decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xwUN5HRRVSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "80d07324-5fd4-46c1-ed10-8cda073f2761"
      },
      "source": [
        "all_outputs = []\n",
        "\n",
        "for compressed_file in glob.glob(os.path.join(OUT_DIR, '*.hfc')):\n",
        "    file_name, _ = os.path.splitext(compressed_file)\n",
        "    output_path = os.path.join(OUT_DIR, f'{file_name}.png')\n",
        "\n",
        "    # Model decode\n",
        "    reconstruction = load_and_decompress(model, compressed_file, output_path)\n",
        "    \n",
        "    all_outputs.append(File(output_path=output_path,\n",
        "                            compressed_path=compressed_file,\n",
        "                            num_bytes=os.path.getsize(compressed_file),\n",
        "                            bpp=get_bpp(Image.open(output_path).size, os.path.getsize(compressed_file))))\n",
        "                            \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQhQQs-CTkgy",
        "colab_type": "text"
      },
      "source": [
        "# Show output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3nVCPeDnskD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1793
        },
        "outputId": "ff427478-8073-4065-b9b7-ad8a8e9f2111"
      },
      "source": [
        "make_cell_large()  # Larger output window.\n",
        "\n",
        "for file in all_outputs:\n",
        "    print_html('<hr/>')\n",
        "    file_name, _ = os.path.splitext(file.output_path)\n",
        "    original_size = original_sizes[os.path.basename(file_name).split('_compressed')[0]]\n",
        "    print(f'Showing {file.output_path} | {file.num_bytes//1000} kB (compressed) | {file.bpp:.4f} bpp | Original: {original_size//1000} kB')\n",
        "    display(Image.open(file.output_path))\n",
        "    print_html('<hr/>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-wkBnyrTAR",
        "colab_type": "text"
      },
      "source": [
        "### Download compressed images\n",
        "\n",
        "Note: Files are losslessly saved as PNG for viewing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn3epZhUYWOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_outputs = True #@param [\"False\", \"True\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BKccvcTpj1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_outputs is True:\n",
        "    ZIP = '/content/hific_compressed_images.zip'\n",
        "\n",
        "    with zipfile.ZipFile(ZIP, 'w') as zf:\n",
        "        for f in all_outputs:\n",
        "            path_with_bpp = f.output_path.replace('.png', f'-{f.bpp:.3f}bpp.png')\n",
        "            zf.write(f.output_path, os.path.basename(path_with_bpp))\n",
        "\n",
        "    files.download(ZIP) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8Jo47741ih",
        "colab_type": "text"
      },
      "source": [
        "# Citation\n",
        "\n",
        "This is a re-implementation of the orignal paper. Please cite the [original paper](https://arxiv.org/abs/2006.09965) if you use their work.\n",
        "\n",
        "```bash\n",
        "@article{mentzer2020high,\n",
        "  title={High-Fidelity Generative Image Compression},\n",
        "  author={Mentzer, Fabian and Toderici, George and Tschannen, Michael and Agustsson, Eirikur},\n",
        "  journal={arXiv preprint arXiv:2006.09965},\n",
        "  year={2020}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWPWkib1Csb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}